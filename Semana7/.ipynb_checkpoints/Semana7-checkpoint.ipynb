{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIIA-4203 MODELOS AVANZADOS PARA ANÁLISIS DE DATOS II\n",
    "\n",
    "\n",
    "# Aprendizaje por transferencia con redes neuronales \n",
    "\n",
    "\n",
    "### Profesor: Camilo Franco (c.franco31@uniandes.edu.co)\n",
    "\n",
    "En este cuadernos estudiaremos una implementación de aprendizaje por transferencia utilizando la red pre-entrenada VGG-16. Implementaremos nuestra propio modelo de aprendizaje por trasferencia utilizando la biblioteca (API) Keras (https://keras.io/). \n",
    "\n",
    "Finalmente evaluaremos si un modelo más complejo de *deep learning* nos permite lograr un mejor desempeño para la detección automática de frailejones sobre imagenes aereas del páramo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero importemos algunos de los paquetes que vamos a utilizar, junto con las imagenes de entrenamiento:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ImportImagenesRGB import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "import datetime\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = import_imagenes_RGB()\n",
    "\n",
    "print(X.shape, Y.shape, X[0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada:**\n",
    "\n",
    "(250, 70, 70, 3) (1, 250) [0.58823529 0.5372549  0.40392157]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Aprendizaje por transferencia\n",
    "\n",
    "En pocas palabras, el aprendizaje por transferencia tiene su historia en la psicología, refiriendose a situaciones donde las personas aplican concimiento, estrategias y aptitudes que han aprendido previamente para enfrentar una nueva situación bajo un contexto **relacionado**. Dentro del aprendizaje computacional, este tipo de aprendizaje se enfoca en guardar un tipo de conocimiento que ya se ha mostrado útil para resolver un problema, y aplicarlo para resolver otro problema distinto pero **relacionado**.\n",
    "\n",
    "Hay que tener en cuenta que si un modelo de transferencia tiene un efecto negativo sobre el desempeño del modelo, entonces tendremos una transferencia negativa (lo cual no es deseable). De este modo, el reto de los métodos de transferencia es el de producir una transferencia positiva entre tareas apropiadamente relacionadas, evitando transferencias negativas entre tareas poco relacionadas (ver Torrey & Shavlik (2009) Transfer learning). \n",
    "\n",
    "El ejemplo que vamos a ver a continuación es un tipo de aprendizaje por transferencia inductivo, característico de las redes neuronales, el cual se ajusta de acuerdo con la coincidencia de un conocimiento previo sobre la fuente de información y la tarea que se propone solucionar. En particular, vamos a llevar a cabo un *aprendizaje por transferencia inductivo-jerárquico*, buscando soluciones a tareas sencillas mediante la combinación de herramientas desarrolladas para tareas más complejas. Entonces, usamos el aprendizaje de una red pre-entrenada, la VGG-16, para aprovechar su conocimiento sobre formas, contornos, bordes, etc. que podemos hacer propias para terminar de entender mejor el problema de clasificación de frailejones, y esperamos mejorar el desempeño de los modelos.\n",
    "\n",
    "\n",
    "### VGG-16\n",
    "\n",
    "La red VGG-16 fue propuesta por Simonyan & Zisserman (2015) en Very deep CNN for large-scale image recognition, siguiendo los principios presentados en Ciresan et al. (2011): Flexible, High Performance Convolutional Neural Networks for Image Classification.\n",
    "\n",
    "La arquitectura de la VGG-16 le permitió ganar la competición ILSVR(Imagenet) 2014 (http://www.image-net.org/challenges/LSVRC/2014/results). Los principios de esta arquitectura consisten en considerar filtros convolucionales pequeños (de $3\\times 3$), que recorren las imagenes exhaustivamente, con un *stride* de 1, y capas de *max-poling* de $2\\times 2$, reduciendo en gran medida el número de hiper-parámetros a optimizar. La red VGG-16 es bastante profunda, con una configuración de 16 capas (con aprox. 138 millones de parámetros): para las primeras 14 capas combina capas convolucionales y capas de agregación, y al final tiene 2 capa densamente conectadas seguidas de una capa de salida *softmax* para clasificación de múltiples clases (ver: https://neurohive.io/en/popular-networks/vgg16/).\n",
    "\n",
    "\n",
    "Implementemos nuestro ejemplo de aprendizaje por transferencia utilizando la red VGG-16, la cual ha sido entrenada previamente con imagenes RGB y que podemos descargar directamente de Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0   = applications.VGG16(include_top=False, weights='imagenet')\n",
    "config_transI = model0.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasamos nuestro conjunto de datos por la red, obteniendo los nuevos patrones de acuerdo con el entendimiento de la red convolucional VGG-16 acerca de las nociones más básicas que encuentra en nuestras imagenes del Páramo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_X = model0.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos unas pocas capas finales para afinar el modelo por transferencia para la tarea específica de detección de imagenes aereas del Páramo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inicializacion Normal\n",
    "initnorm = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=1)\n",
    "\n",
    "model = Sequential()  \n",
    "model.add(Flatten(input_shape=feat_X.shape[1:]))  \n",
    "model.add(Dense(5, activation='sigmoid', kernel_initializer=initnorm, bias_initializer='zeros'))  \n",
    "model.add(Dense(1, activation='sigmoid', kernel_initializer=initnorm, bias_initializer='zeros')) \n",
    "\n",
    "config_transF = model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y entrenamos esas capas finales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos la tabla donde guardamos los resultados\n",
    "x = PrettyTable([\"Exac_E\", \"Exac_V\", \"Exac_P\", \"Epoca\"])\n",
    "\n",
    "# Definimos el número máximo de iteraciones (épocas de la red)\n",
    "epocas=100\n",
    "\n",
    "# Definimos los parametros del Adam\n",
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "# Inicializamos el error \n",
    "err_p = 999\n",
    "\n",
    "for i in range(0,3,1):\n",
    "    r = i^3\n",
    "    CE_x, CV0_x, CE_y, CV0_y = train_test_split(feat_X, Y.T, test_size = 0.3, random_state = r)\n",
    "    CV_x, CP_x, CV_y, CP_y = train_test_split(CV0_x, CV0_y, test_size = 0.5, random_state = r)\n",
    "       \n",
    "    # Definimos la arquitectura de la red\n",
    "    model = Sequential.from_config(config_transF)\n",
    "    \n",
    "    # Definimos el método de optimización con respecto a su funcion de perdida (además guardamos la exactitud para cada iteracion)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    \n",
    "    # Ajustamos el modelo\n",
    "    history=model.fit(x=CE_x, y=CE_y, epochs=epocas, validation_data=(CV_x, CV_y), verbose=0, shuffle=False)\n",
    "    \n",
    "    # Encontramos el mejor modelo en validación\n",
    "    min_err=np.min(history.history['val_loss'])\n",
    "    best_epoc=np.where(history.history['val_loss'] == min_err)[0] \n",
    "        \n",
    "    # Conseguimos el mejor modelo de acuerdo con su desempeño en validación\n",
    "    model.fit(x=CE_x, y=CE_y, epochs=best_epoc[0], validation_data=(CV_x, CV_y), verbose=0, shuffle=False)\n",
    "            \n",
    "    # Calculamos las metricas\n",
    "    train_metrics = model.evaluate(x=CE_x, y=CE_y, verbose=0)\n",
    "    valid_metrics = model.evaluate(x=CV_x, y=CV_y, verbose=0)\n",
    "    test_metrics = model.evaluate(x=CP_x, y=CP_y, verbose=0)\n",
    "    \n",
    "    # Guardamos las métricas de desempeño\n",
    "    accu_e = train_metrics[1]\n",
    "    loss_e = train_metrics[0]\n",
    "    accu_v = valid_metrics[1]\n",
    "    loss_v = valid_metrics[0]\n",
    "    accu_p = test_metrics[1]\n",
    "    loss_p = test_metrics[0]\n",
    "    \n",
    "    if (loss_p < err_p):\n",
    "        pathr =('Transfer_Adam_partseed='+str(r)+'.h5')\n",
    "        model.save(pathr) \n",
    "        err_p = loss_p\n",
    "    \n",
    "    # Imprimimos el desempeño para cada repetición\n",
    "    print('Epoca= '+str(best_epoc[0])+' , accu_v1='+str(accu_v) +' , accu_v2='+str(accu_p))\n",
    "    \n",
    "    x.add_row([np.round(accu_e,4), np.round(accu_v,4), np.round(accu_p,4), best_epoc[0]])\n",
    "\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos el desempeño del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['accuracy'])  \n",
    "plt.plot(history.history['val_accuracy'])  \n",
    "plt.title('Exactitud')  \n",
    "plt.ylabel('Acc')  \n",
    "plt.xlabel('Epoca')  \n",
    "plt.legend(['Entreno', 'Validacion'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(1) \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('Pérdida')  \n",
    "plt.ylabel('Pérdida')  \n",
    "plt.xlabel('Epoca')  \n",
    "plt.legend(['Entreno', 'Validación'], loc='upper right')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el mejor modelo y confirmamos el desempeño del modelo sobre todo el conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# red convolucional\n",
    "model_4 = load_model('Transfer_Adam_partseed=1.h5')\n",
    "\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el desempeño del mejor modelo sobre todo el conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model_4.predict(feat_X)\n",
    "Y_preds = (Y_pred > 0.5)\n",
    "\n",
    "confusion_matrix(Y.T, Y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada:**\n",
    "    \n",
    "<table style=\"width:20%\">\n",
    "    <tr>\n",
    "       <td> 144 </td>\n",
    "       <td> 1 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> 0 </td>\n",
    "       <td> 105 </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que el desempeño del modelo a mejorado bastante. \n",
    "\n",
    "### Ejercicio 1.1\n",
    "\n",
    "Encuentre el mejor modelo examinando una configuración distinta para las capas de salida, o siguiendo alguna otra estrategia como puede ser cambiando el optimizador o las funciones de activación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Caso aplicado\n",
    "\n",
    "Ahora probemos nuestro modelo sobre la imagen completa de prueba del paramo ``IMG_3451.JPG``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import image\n",
    "\n",
    "img = image.load_img('IMG_3451.JPG')\n",
    "img "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Red sencilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# red sencilla 5 neuronas\n",
    "model_1 = load_model('modelo_redsencilla_initseed=1_part_seed=3numn=5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo pasamos por nuestra imagen de prueba\n",
    "x = np.array(img)\n",
    "x2 = x\n",
    "\n",
    "ni = x.shape[0]-50\n",
    "mi = x.shape[1]-50\n",
    "\n",
    "f1=0\n",
    "f2=70\n",
    "for i in range(1,ni,50):\n",
    "    c1=0\n",
    "    c2=70\n",
    "    for j in range(1,mi,50):\n",
    "        subi=x[f1:f2,c1:c2,]/255.\n",
    "        subi2=np.expand_dims(subi,0)\n",
    "        Y_preds = model_1.predict(subi2)\n",
    "        pred_P = (Y_preds > 0.5)\n",
    "        if(pred_P==1):\n",
    "            x2[f1:f2,c1:c2,2]=0\n",
    "        c1=c1+50\n",
    "        c2=c2+50\n",
    "    f1=f1+50\n",
    "    f2=f2+50\n",
    "        \n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Red multi-capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# red profunda de 6 capas\n",
    "model_2 = load_model('modelo_redprofunda_initseed=1_part_seed=8_Init=Normal.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo pasamos por nuestra imagen de prueba\n",
    "x = np.array(img)\n",
    "x2 = x\n",
    "\n",
    "ni = x.shape[0]-50\n",
    "mi = x.shape[1]-50\n",
    "\n",
    "f1=0\n",
    "f2=70\n",
    "for i in range(1,ni,50):\n",
    "    c1=0\n",
    "    c2=70\n",
    "    for j in range(1,mi,50):\n",
    "        subi=x[f1:f2,c1:c2,]/255.\n",
    "        subi2=np.expand_dims(subi,0)\n",
    "        Y_preds = model_2.predict(subi2)\n",
    "        pred_P = (Y_preds > 0.5)\n",
    "        if(pred_P==1):\n",
    "            x2[f1:f2,c1:c2,2]=0\n",
    "        c1=c1+50\n",
    "        c2=c2+50\n",
    "    f1=f1+50\n",
    "    f2=f2+50\n",
    "        \n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Red Convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# red convolucional sencilla\n",
    "model_3 = load_model('modelo_CNN_initseed=1_part_seed=3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo pasamos por nuestra imagen de prueba\n",
    "x = np.array(img)\n",
    "x2 = x\n",
    "\n",
    "ni = x.shape[0]-50\n",
    "mi = x.shape[1]-50\n",
    "\n",
    "f1=0\n",
    "f2=70\n",
    "for i in range(1,ni,50):\n",
    "    c1=0\n",
    "    c2=70\n",
    "    for j in range(1,mi,50):\n",
    "        subi=x[f1:f2,c1:c2,]/255.\n",
    "        subi2=np.expand_dims(subi,0)\n",
    "        Y_preds = model_3.predict(subi2)\n",
    "        pred_P = (Y_preds > 0.5)\n",
    "        if(pred_P==1):\n",
    "            x2[f1:f2,c1:c2,2]=0\n",
    "        c1=c1+50\n",
    "        c2=c2+50\n",
    "    f1=f1+50\n",
    "    f2=f2+50\n",
    "        \n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Red Convolucional VGG-16 con transferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lo pasamos por nuestra imagen de prueba\n",
    "x = np.array(img)\n",
    "x2 = x\n",
    "\n",
    "ni = x.shape[0]-50\n",
    "mi = x.shape[1]-50\n",
    "\n",
    "f1=0\n",
    "f2=70\n",
    "for i in range(1,ni,50):\n",
    "    c1=0\n",
    "    c2=70\n",
    "    for j in range(1,mi,50):\n",
    "        subi=x[f1:f2,c1:c2,]/255.\n",
    "        subi2=np.expand_dims(subi,0)\n",
    "        feat_subi2 = model0.predict(subi2)\n",
    "        Y_preds = model_4.predict(feat_subi2)\n",
    "        pred_P = (Y_preds > 0.5)\n",
    "        if(pred_P==1):\n",
    "            x2[f1:f2,c1:c2,2]=0\n",
    "        c1=c1+50\n",
    "        c2=c2+50\n",
    "    f1=f1+50\n",
    "    f2=f2+50\n",
    "        \n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 2.1\n",
    "\n",
    "¿Qué puede observar sobre el desempeño de los diferentes modelos? Argumente cuál es el mejor modelo para poner en producción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.2\n",
    "\n",
    "Investigue otra red pre-entrenada dsitinta a la VGG-16 e implemente el aprendizaje por transferencia para la deteccion de frailejones. Argumente por qué su justifica el aprendizaje por transferencia con base en el modelo pre-entrenado de su elección (cómo se relacionan la tarea base y la segunda tarea objetivo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.3\n",
    "Construya un algoritmo que utilice el mejor modelo de red neuronal para la detección de poblaciones en la imagen completa IMG_3451.JPG, y estime la densidad para cada población detectada.\n",
    "\n",
    "*Ayuda:* Mediante un procedimiento sencillo, primero detecte las poblaciones de frailejones y luego estime su densidad, calculada como el numero de frailejones por area poblada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "c4HO0",
   "launcher_item_id": "lSYZM"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
